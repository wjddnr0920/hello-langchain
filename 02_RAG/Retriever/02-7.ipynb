{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "136402ce",
   "metadata": {},
   "source": [
    "### Ensemble Retriever (하이브리드 검색)\n",
    "- 여러 검색 방식을 결합하여 검색 품질을 향상시키는 기법\n",
    "\n",
    "- 일반적인 조합은 **BM25 키워드 검색**과 **벡터 유사도 검색**을 결합하는 하이브리드 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f65847fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 6개의 문서 준비 완료\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "# LangChain 관련 기술 문서 샘플\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=\"LangChain은 대규모 언어 모델(LLM)을 활용한 애플리케이션 개발 프레임워크입니다. \"\n",
    "                     \"체인, 에이전트, 메모리 등의 핵심 개념을 제공합니다.\",\n",
    "        metadata={\"source\": \"langchain_intro\", \"category\": \"overview\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"RAG(Retrieval-Augmented Generation)는 검색 증강 생성 기법으로, \"\n",
    "                     \"외부 문서를 검색하여 LLM의 응답 품질을 향상시킵니다.\",\n",
    "        metadata={\"source\": \"rag_intro\", \"category\": \"rag\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"벡터 데이터베이스는 임베딩 벡터를 저장하고 유사도 검색을 수행합니다. \"\n",
    "                     \"FAISS, Chroma, Pinecone 등이 대표적입니다.\",\n",
    "        metadata={\"source\": \"vectordb\", \"category\": \"database\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"BM25는 키워드 기반 검색 알고리즘으로, TF-IDF를 개선한 방식입니다. \"\n",
    "                     \"정확한 키워드 매칭에 강점이 있습니다.\",\n",
    "        metadata={\"source\": \"bm25\", \"category\": \"search\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"하이브리드 검색은 키워드 검색과 시맨틱 검색을 결합합니다. \"\n",
    "                     \"BM25와 벡터 검색의 장점을 모두 활용할 수 있습니다.\",\n",
    "        metadata={\"source\": \"hybrid\", \"category\": \"search\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"임베딩 모델은 텍스트를 벡터로 변환합니다. \"\n",
    "                     \"OpenAI, HuggingFace, Cohere 등에서 다양한 모델을 제공합니다.\",\n",
    "        metadata={\"source\": \"embedding\", \"category\": \"model\"}\n",
    "    ),\n",
    "]\n",
    "\n",
    "print(f\"총 {len(documents)}개의 문서 준비 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cccfabcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== BM25 검색 결과 ===\n",
      "1. [embedding] 임베딩 모델은 텍스트를 벡터로 변환합니다. OpenAI, HuggingFace, Coher...\n",
      "2. [hybrid] 하이브리드 검색은 키워드 검색과 시맨틱 검색을 결합합니다. BM25와 벡터 검색의 장점을 ...\n",
      "3. [bm25] BM25는 키워드 기반 검색 알고리즘으로, TF-IDF를 개선한 방식입니다. 정확한 키워드...\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.retrievers import BM25Retriever\n",
    "\n",
    "# BM25 검색기 생성\n",
    "bm25_retriever = BM25Retriever.from_documents(\n",
    "    documents=documents,\n",
    "    k=3  # 상위 3개 문서 반환\n",
    ")\n",
    "\n",
    "# BM25 검색 테스트\n",
    "query = \"BM25 알고리즘의 특징\"\n",
    "bm25_results = bm25_retriever.invoke(query)\n",
    "\n",
    "print(\"=== BM25 검색 결과 ===\")\n",
    "for i, doc in enumerate(bm25_results, 1):\n",
    "    print(f\"{i}. [{doc.metadata['source']}] {doc.page_content[:50]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d896e875",
   "metadata": {},
   "source": [
    "**한국어 토크나이저 설정 (kiwipiepy)**\n",
    "\n",
    "BM25는 기본적으로 공백 기반 토큰화를 사용하는데, 한국어는 교착어로 형태소 분석이 필요합니다.\n",
    "\n",
    "kiwipiepy를 사용하면 한국어 검색 성능을 크게 향상시킬 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa6c5612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Kiwi 형태소 분석 결과 ===\n",
      "  LangChain  | SL    | 위치: 0-9\n",
      "  은          | JX    | 위치: 9-10\n",
      "  대          | XPN   | 위치: 11-12\n",
      "  규모         | NNG   | 위치: 12-14\n",
      "  언어         | NNG   | 위치: 15-17\n",
      "  모델         | NNG   | 위치: 18-20\n",
      "  을          | JKO   | 위치: 20-21\n",
      "  활용         | NNG   | 위치: 22-24\n",
      "  하          | XSV   | 위치: 24-25\n",
      "  ᆫ          | ETM   | 위치: 24-25\n",
      "  애플리케이션     | NNG   | 위치: 26-32\n",
      "  개발         | NNG   | 위치: 33-35\n",
      "  프레임        | NNG   | 위치: 36-39\n",
      "  워크         | NNG   | 위치: 39-41\n",
      "  이          | VCP   | 위치: 41-42\n",
      "  ᆸ니다        | EF    | 위치: 41-44\n",
      "  .          | SF    | 위치: 44-45\n"
     ]
    }
   ],
   "source": [
    "from kiwipiepy import Kiwi\n",
    "\n",
    "# Kiwi 형태소 분석기 초기화\n",
    "kiwi = Kiwi()\n",
    "\n",
    "# 형태소 분석 테스트\n",
    "text = \"LangChain은 대규모 언어 모델을 활용한 애플리케이션 개발 프레임워크입니다.\"\n",
    "tokens = kiwi.tokenize(text)\n",
    "\n",
    "print(\"=== Kiwi 형태소 분석 결과 ===\")\n",
    "for token in tokens:\n",
    "    print(f\"  {token.form:10} | {token.tag:5} | 위치: {token.start}-{token.start + token.len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4e204f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "토큰화 결과: ['금융', '보험', '은', '장기', '적', '이', 'ᆫ', '자산', '관리', '상품', '이', 'ᆸ니다', '.']\n"
     ]
    }
   ],
   "source": [
    "from kiwipiepy import Kiwi\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "\n",
    "# Kiwi 초기화\n",
    "kiwi = Kiwi()\n",
    "\n",
    "def kiwi_tokenize(text: str) -> list[str]:\n",
    "    \"\"\"Kiwi를 사용한 한국어 토크나이저\"\"\"\n",
    "    tokens = kiwi.tokenize(text)\n",
    "    # 형태소(form)만 추출하여 리스트로 반환\n",
    "    return [token.form for token in tokens]\n",
    "\n",
    "# 테스트\n",
    "print(\"토큰화 결과:\", kiwi_tokenize(\"금융보험은 장기적인 자산 관리 상품입니다.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ad06e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Kiwi 적용 BM25 검색 결과 ===\n",
      "1. [langchain_intro] LangChain은 대규모 언어 모델(LLM)을 활용한 애플리케이션 개발 프레임워크입니다....\n",
      "2. [embedding] 임베딩 모델은 텍스트를 벡터로 변환합니다. OpenAI, HuggingFace, Coher...\n",
      "3. [hybrid] 하이브리드 검색은 키워드 검색과 시맨틱 검색을 결합합니다. BM25와 벡터 검색의 장점을 ...\n"
     ]
    }
   ],
   "source": [
    "# Kiwi 토크나이저를 적용한 BM25 Retriever 생성\n",
    "bm25_retriever_kiwi = bm25_retriever.from_documents(\n",
    "    documents,\n",
    "    k=3,\n",
    "    preprocess_func=kiwi_tokenize\n",
    ")\n",
    "\n",
    "# 검색 테스트\n",
    "query = \"언어 모델 프레임워크\"\n",
    "results = bm25_retriever_kiwi.invoke(query)\n",
    "\n",
    "print(\"=== Kiwi 적용 BM25 검색 결과 ===\")\n",
    "for i, doc in enumerate(results, 1):\n",
    "    print(f\"{i}. [{doc.metadata['source']}] {doc.page_content[:50]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf82ff92",
   "metadata": {},
   "source": [
    "검색 품질을 높이려면 명사만 추출하는 것이 효과적일 수 있습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5f8d294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 형태소: ['LangChain', '은', '대', '규모', '언어', '모델', '을', '활용', '하', 'ᆫ', '애플리케이션', '개발', '프레임', '워크', '이', 'ᆸ니다', '.']\n",
      "명사만 추출: ['규모', '언어', '모델', '활용', '애플리케이션', '개발', '프레임', '워크']\n"
     ]
    }
   ],
   "source": [
    "def kiwi_tokenize_nouns(text: str) -> list[str]:\n",
    "    \"\"\"명사(NNG, NNP)만 추출하는 토크나이저\"\"\"\n",
    "    tokens = kiwi.tokenize(text)\n",
    "    # 일반명사(NNG), 고유명사(NNP)만 추출\n",
    "    return [token.form for token in tokens if token.tag in (\"NNG\", \"NNP\")]\n",
    "\n",
    "# 테스트\n",
    "text = \"LangChain은 대규모 언어 모델을 활용한 애플리케이션 개발 프레임워크입니다.\"\n",
    "print(\"전체 형태소:\", kiwi_tokenize(text))\n",
    "print(\"명사만 추출:\", kiwi_tokenize_nouns(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ff78a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Kiwi 적용 BM25 검색 결과 ===\n",
      "1. [bm25] BM25는 키워드 기반 검색 알고리즘으로, TF-IDF를 개선한 방식입니다. 정확한 키워드...\n",
      "2. [hybrid] 하이브리드 검색은 키워드 검색과 시맨틱 검색을 결합합니다. BM25와 벡터 검색의 장점을 ...\n",
      "3. [embedding] 임베딩 모델은 텍스트를 벡터로 변환합니다. OpenAI, HuggingFace, Coher...\n"
     ]
    }
   ],
   "source": [
    "# 검색 테스트\n",
    "query = \"BM25 알고리즘의 특징\"\n",
    "results = bm25_retriever_kiwi.invoke(query)\n",
    "\n",
    "print(\"=== Kiwi 적용 BM25 검색 결과 ===\")\n",
    "for i, doc in enumerate(results, 1):\n",
    "    print(f\"{i}. [{doc.metadata['source']}] {doc.page_content[:50]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e282d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "쿼리: 'BM25 알고리즘의 특징'\n",
      "\n",
      "=== 기본 BM25 ===\n",
      "  1. embedding\n",
      "  2. hybrid\n",
      "\n",
      "=== Kiwi BM25 ===\n",
      "  1. bm25\n",
      "  2. hybrid\n"
     ]
    }
   ],
   "source": [
    "# 기본 BM25 (공백 기반)\n",
    "bm25_default = BM25Retriever.from_documents(documents, k=3)\n",
    "\n",
    "# Kiwi 적용 BM25\n",
    "bm25_kiwi = BM25Retriever.from_documents(\n",
    "    documents, \n",
    "    k=3, \n",
    "    preprocess_func=kiwi_tokenize\n",
    ")\n",
    "\n",
    "def compare_bm25(query: str):\n",
    "    \"\"\"기본 BM25와 Kiwi BM25 비교\"\"\"\n",
    "    print(f\"쿼리: '{query}'\\n\")\n",
    "\n",
    "    print(\"=== 기본 BM25 ===\")\n",
    "    for i, doc in enumerate(bm25_default.invoke(query)[:2], 1):\n",
    "        print(f\"  {i}. {doc.metadata['source']}\")\n",
    "\n",
    "    print(\"\\n=== Kiwi BM25 ===\")\n",
    "    for i, doc in enumerate(bm25_kiwi.invoke(query)[:2], 1):\n",
    "        print(f\"  {i}. {doc.metadata['source']}\")\n",
    "\n",
    "compare_bm25(\"BM25 알고리즘의 특징\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "215f0752",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Portfolio\\Study\\hello-langchain\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 벡터 검색 결과 ===\n",
      "1. [bm25] BM25는 키워드 기반 검색 알고리즘으로, TF-IDF를 개선한 방식입니다. 정확한 키워드...\n",
      "2. [hybrid] 하이브리드 검색은 키워드 검색과 시맨틱 검색을 결합합니다. BM25와 벡터 검색의 장점을 ...\n",
      "3. [rag_intro] RAG(Retrieval-Augmented Generation)는 검색 증강 생성 기법으로...\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# 임베딩 모델 초기화\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# FAISS 벡터스토어 생성\n",
    "vectorstore = FAISS.from_documents(documents, embeddings)\n",
    "\n",
    "# 벡터 검색기 생성\n",
    "vector_retriever = vectorstore.as_retriever(search_kwargs={'k': 3})\n",
    "\n",
    "# 벡터 검색 테스트\n",
    "vector_results = vector_retriever.invoke(query)\n",
    "\n",
    "print(\"=== 벡터 검색 결과 ===\")\n",
    "for i, doc in enumerate(vector_results, 1):\n",
    "    print(f\"{i}. [{doc.metadata['source']}] {doc.page_content[:50]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed8d9ba",
   "metadata": {},
   "source": [
    "**FAISS와 BF25 앙상블**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c35dac8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Ensemble 검색 결과 ===\n",
      "1. [bm25] BM25는 키워드 기반 검색 알고리즘으로, TF-IDF를 개선한 방식입니다. 정확한 키워드...\n",
      "2. [hybrid] 하이브리드 검색은 키워드 검색과 시맨틱 검색을 결합합니다. BM25와 벡터 검색의 장점을 ...\n",
      "3. [embedding] 임베딩 모델은 텍스트를 벡터로 변환합니다. OpenAI, HuggingFace, Coher...\n",
      "4. [rag_intro] RAG(Retrieval-Augmented Generation)는 검색 증강 생성 기법으로...\n"
     ]
    }
   ],
   "source": [
    "from langchain_classic.retrievers import EnsembleRetriever\n",
    "\n",
    "# Kiwi 토크나이저를 적용한 BM25와 벡터 검색 결합\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_kiwi, vector_retriever],\n",
    "    weights=[0.5, 0.5]\n",
    ")\n",
    "\n",
    "# Ensemble 검색 테스트\n",
    "query = \"BM25 알고리즘의 특징\"\n",
    "ensemble_results = ensemble_retriever.invoke(query)\n",
    "\n",
    "print(\"=== Ensemble 검색 결과 ===\")\n",
    "for i, doc in enumerate(ensemble_results, 1):\n",
    "    print(f\"{i}. [{doc.metadata['source']}] {doc.page_content[:50]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90091dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "쿼리: '대규모 언어 모델 애플리케이션 개발'\n",
      "\n",
      "=== BM25 우선 (BM25:0.7, Vector:0.3) ===\n",
      "  1. [langchain_intro]\n",
      "  2. [embedding]\n",
      "  3. [hybrid]\n",
      "\n",
      "=== 균형 (BM25:0.5, Vector:0.5) ===\n",
      "  1. [langchain_intro]\n",
      "  2. [embedding]\n",
      "  3. [hybrid]\n",
      "\n",
      "=== 벡터 우선 (BM25:0.3, Vector:0.7) ===\n",
      "  1. [langchain_intro]\n",
      "  2. [embedding]\n",
      "  3. [rag_intro]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 다양한 가중치 조합 테스트\n",
    "weight_configs = [\n",
    "    ([0.7, 0.3], \"BM25 우선\"),      # 키워드 매칭 중시\n",
    "    ([0.5, 0.5], \"균형\"),           # 균형 잡힌 접근\n",
    "    ([0.3, 0.7], \"벡터 우선\"),      # 의미적 유사도 중시\n",
    "]\n",
    "\n",
    "query = \"대규모 언어 모델 애플리케이션 개발\"\n",
    "\n",
    "print(f\"쿼리: '{query}'\\n\")\n",
    "\n",
    "for weights, description in weight_configs:\n",
    "    ensemble = EnsembleRetriever(\n",
    "        retrievers=[bm25_kiwi, vector_retriever],\n",
    "        weights=weights\n",
    "    )\n",
    "    results = ensemble.invoke(query)\n",
    "\n",
    "    print(f\"=== {description} (BM25:{weights[0]}, Vector:{weights[1]}) ===\")\n",
    "    for i, doc in enumerate(results[:3], 1):\n",
    "        print(f\"  {i}. [{doc.metadata['source']}]\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bcf2842b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문: 하이브리드 검색의 장점은 무엇인가요?\n",
      "답변: 하이브리드 검색의 장점은 키워드 검색과 시맨틱 검색의 장점을 모두 활용할 수 있다는 점입니다. 이를 통해 사용자는 정확한 키워드 매칭을 통해 필요한 정보를 빠르게 찾을 수 있으며, 동시에 시맨틱 검색을 통해 더 넓은 의미의 관련 정보를 탐색할 수 있습니다. 이로 인해 검색 결과의 품질과 다양성이 향상되며, 사용자의 의도에 맞는 보다 정확하고 유용한 정보를 제공할 수 있습니다. 또한, BM25와 벡터 검색의 조합으로 인해 검색의 정확성과 유연성이 모두 강화됩니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# LLM 초기화\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# 프롬프트 템플릿\n",
    "template = \"\"\"다음 컨텍스트를 기반으로 질문에 답변하세요.\n",
    "\n",
    "컨텍스트:\n",
    "{context}\n",
    "\n",
    "질문: {question}\n",
    "\n",
    "답변:\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# 문서 포맷팅 함수\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# RAG 체인 구성\n",
    "rag_chain = (\n",
    "    {\"context\": ensemble_retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 질의응답 실행\n",
    "question = \"하이브리드 검색의 장점은 무엇인가요?\"\n",
    "answer = rag_chain.invoke(question)\n",
    "\n",
    "print(f\"질문: {question}\")\n",
    "print(f\"답변: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660453fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
